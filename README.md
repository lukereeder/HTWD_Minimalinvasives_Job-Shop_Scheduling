# Minimalinvasives Job-Shop Scheduling


# ğŸ§® Projektsetup

Dieses Projekt nutzt verschiedene Python-Bibliotheken fÃ¼r Datenanalyse, Simulation und Optimierung. Unten findest du die Anweisungen zur Installation der AbhÃ¤ngigkeiten â€“ jeweils fÃ¼r **Windows** und **Unix-basierte Systeme** (Linux, macOS).

---

## ğŸ› ï¸ Installation

### ğŸ”¹ Voraussetzungen

- **Python 3.10 oder hÃ¶her**
- **Aktuelle pip-Version**
- Optional: Verwendung einer **virtuellen Umgebung**

---

### ğŸªŸ Installation unter Windows

```cmd
:: Virtuelle Umgebung erstellen (optional, empfohlen)
python -m venv venv
venv\Scripts\activate
```

```cmd
:: pip aktualisieren
python -m pip install --upgrade pip
```

```cmd
:: Pakete installieren
pip install pandas matplotlib simpy pulp ortools editdistance scipy sqlalchemy colorama yagmail scikit-learn python-dotenv seaborn tomli
```
---

### ğŸ§ Installation unter Linux / macOS

```bash
# Virtuelle Umgebung erstellen (optional, empfohlen)
python3 -m venv venv
source venv/bin/activate
```

```bash
# pip aktualisieren
python3 -m pip install --upgrade pip
```

```bash
# Pakete installieren
python3 -m pip install pandas matplotlib simpy pulp ortools editdistance scipy sqlalchemy colorama yagmail scikit-learn python-dotenv seaborn tomli
```

---

## â–¶ï¸ Zeitgewichtetes Constraint-Programming im Rolling-Horizon-Framework

Dieses Repository enthÃ¤lt eine Constraint-Programming-Variante, die die **Start-Abweichung** (Deviation) zeitabhÃ¤ngig gewichtet:
Ã„nderungen an Operationen, die **nah** an der aktuellen Schicht liegen, werden **teurer** als Ã„nderungen weit in der Zukunft.

### ğŸ”„ Integration: twdev im Rolling-Horizon mit StÃ¶rszenarien

Die zeitgewichtete Deviation (twdev) wurde in das bestehende Rolling-Horizon-Framework integriert und kann mit verschiedenen StÃ¶rszenarien getestet werden:
- âœ… **Stochastische Varianz (Sigma)** - Lognormal-verteilte StÃ¶rungen der Operationsdauern
- âœ… **Maschinenblockaden** - Deterministische MaschinenausfÃ¤lle
- âœ… **Kombinierte StÃ¶rungen** - Beide Szenarien gleichzeitig

#### 1) Daten/Datenbank vorbereiten (einmalig)

```bash
python3 00_Problem_Generation/all.py
```

Hinweis: dabei werden Tabellen zurÃ¼ckgesetzt und der Datensatz `Fisher and Thompson 10x10` (Routings, Jobs, Due Dates, Transition Times) in `experiments.db` aufgebaut.

#### 2) Rolling-Horizon-Experimente ausfÃ¼hren

**Standard-Deviation (Original-Framework):**
```bash
python3 run_cp_experiments.py --util 0.75 --sigma 0.1 --time_limit 1800 --bound_no_improvement_time 600 --bound_warmup_time 60
```

**Time-Weighted-Deviation (twdev - Neue Methode):**
```bash
python3 run_cp_experiments.py --util 0.75 --sigma 0.1 --time_limit 1800 --bound_no_improvement_time 600 --bound_warmup_time 60 --use_time_weighted_deviation --deviation_window_minutes 480 --deviation_bucket_minutes 60
```

**Mit Maschinenblockade:**
```bash
python3 run_cp_experiments.py --util 0.75 --sigma 0.1 --time_limit 1800 --bound_no_improvement_time 600 --bound_warmup_time 60 --machine_blockade M00:1500:1560
```

**Direkter Vergleich (Standard vs. twdev):**
```bash
python3 run_cp_twdev_comparison.py --util 0.75 --sigma 0.1 --time_limit 1800 --bound_no_improvement_time 600 --bound_warmup_time 60
```

**Vergleich mit Maschinenblockade:**
```bash
python3 run_cp_twdev_comparison.py --util 0.75 --sigma 0.1 --time_limit 1800 --bound_no_improvement_time 600 --bound_warmup_time 60 --machine_blockade M00:1500:1560
```

Ausgaben:
- **Datenbank**: Schedule/Simulation werden in `experiments.db` gespeichert
- **Logs**: Solver-Logs fÃ¼r jede Schicht in `data/solver_logs/`
- **Vergleichsergebnisse**: JSON-Datei mit Shift-Summaries in `data/output/twdev_comparison/`

#### 3) Finale Experimente (alle Szenarien)

```bash
./run_all_final_experiments.sh
```

FÃ¼hrt 12 systematische Experimente durch:
- Szenario 1: Nur stochastische Varianz (3 Tests)
- Szenario 2: Nur Maschinenblockade (3 Tests)
- Szenario 3: Kombinierte StÃ¶rungen (4 Tests)
- Szenario 4: Extreme Bedingungen (2 Tests)

#### 4) Ergebnisse analysieren

```bash
python3 analyze_final_results.py
```

Erstellt:
- Zusammenfassungstabelle aller Experimente
- Ãœbersichts-Visualisierungen
- CSV-Export fÃ¼r weitere Analysen

---

## ğŸ“‚ Neue und geÃ¤nderte Dateien (Projektarbeit)

### ğŸ†• Neue Dateien

| Datei | Beschreibung |
|-------|--------------|
| **`run_cp_twdev_comparison.py`** | Vergleichsskript: Standard-Deviation vs. Time-Weighted-Deviation im Rolling-Horizon-Framework |
| **`run_all_final_experiments.sh`** | Batch-Skript: 12 systematische Experimente mit allen StÃ¶rszenarien |
| **`analyze_final_results.py`** | Analyse-Skript: Zusammenfassung und Visualisierung aller Experimente |
| **`test_twdev_integration.py`** | Schnelltest: ÃœberprÃ¼ft twdev-Integration (2 Shifts) |
| **`test_machine_blockade.py`** | Test: ÃœberprÃ¼ft Maschinenblockaden-FunktionalitÃ¤t |
| **`test_alpha_weights.py`** | Unit-Test: PrÃ¼ft die acht Alpha-Gewichtungsfaktoren |
| **`test_quick_scenarios.py`** | Test: Deterministisches Baseline und twdev+Blockade |

---

### âœï¸ GeÃ¤nderte Dateien mit Zeilenreferenzen

#### `src/solvers/CP_Solver.py`

| Was wurde hinzugefÃ¼gt? |
|------------------------|
| Neue Methode `build_model__absolute_lateness__time_weighted_start_deviation__minimization()` â€“ kombiniert VerspÃ¤tung + VerfrÃ¼hung + **zeitgewichtete Abweichung** |
| Neue Hilfsmethode `_add_time_weighted_start_deviation_var()` â€“ berechnet Gewicht basierend auf zeitlicher NÃ¤he zur Schicht |
| Parameter `machine_blockades` im `__init__` â€“ ermÃ¶glicht deterministische MaschinenausfÃ¤lle |
| Maschinenblockaden-Constraints in `_add_machine_no_overlap_constraints()` â€“ blockiert Maschinen fÃ¼r definierte ZeitrÃ¤ume |

#### `src/CP_Experiment_Runner.py`

| Was wurde hinzugefÃ¼gt? |
|------------------------|
| Neue Parameter fÃ¼r `use_time_weighted_deviation`, `deviation_window_minutes`, `deviation_bucket_minutes`, `deviation_max_factor`, `machine_blockades` |
| Bedingte Solver-Auswahl: twdev vs. Standard-Deviation basierend auf `use_time_weighted_deviation` |
| Automatische Erkennung aktiver Blockaden pro Shift |

#### `run_cp_experiments.py`

| Was wurde hinzugefÃ¼gt? |
|------------------------|
| CLI-Argumente fÃ¼r twdev-Parameter (`--use_time_weighted_deviation`, `--deviation_window_minutes`, etc.) |
| CLI-Argument fÃ¼r Maschinenblockaden (`--machine_blockade`, mehrfach verwendbar) |
| Ãœbergabe der twdev- und Blockaden-Parameter an `run_experiment()` |

#### `src/solvers/CP_Collections.py`

| Was wurde hinzugefÃ¼gt? |
|------------------------|
| Neue Klasse `WeightedCostVarCollection` â€“ erlaubt individuelle Gewichte pro Variable (fÃ¼r zeitgewichtete Abweichung) |

#### `src/DataFrameAnalyses.py`

| Zeile | Ã„nderung |
|-------|----------|
| **1** | `from __future__ import annotations` hinzugefÃ¼gt (Python 3.9 KompatibilitÃ¤t fÃ¼r `list[...]` Type Hints) |

#### `src/analyses/fig_startdeviation.py`

| Zeile | Ã„nderung |
|-------|----------|
| **1** | `from __future__ import annotations` hinzugefÃ¼gt |

#### `src/analyses/fig_tardiness_earliness.py`

| Zeile | Ã„nderung |
|-------|----------|
| **1** | `from __future__ import annotations` hinzugefÃ¼gt |

#### `README.md`

| Abschnitt | Ã„nderung |
|-----------|----------|
| Ende | Dokumentation fÃ¼r eigenen Solver + DateiÃ¼bersicht hinzugefÃ¼gt |

---

## ğŸ”‘ Kernkonzepte der Implementierung

### 1. Makespan-Minimierung (Baseline)
```
Zielfunktion: minimiere(makespan)
              wobei makespan = max(Endzeit_i) Ã¼ber alle Operationen
```

### 2. Neuplanung mit Kostentermen
```
Zielfunktion: minimiere(
    Gewicht_VerspÃ¤tung Ã— Î£ VerspÃ¤tung_j        # Tardiness
  + Gewicht_VerfrÃ¼hung Ã— Î£ VerfrÃ¼hung_j        # Earliness  
  + Gewicht_Abweichung Ã— Î£ Zeitgewicht_i Ã— |Startzeit_i - Startzeit_i_alt|   # Deviation
)
```

### 3. Zeitgewichtete Abweichung (time-weighted deviation)
Operationen, die nÃ¤her am aktuellen Zeitpunkt liegen, bekommen ein **hÃ¶heres Gewicht**:
```
Bucket 0 (0â€“60 Minuten):   Gewicht = Maximalfaktor
Bucket 1 (60â€“120 Minuten): Gewicht = Maximalfaktor - 1
...
Bucket n (> Zeitfenster):  Gewicht = 1
```

---

## ğŸ§ª Tests und Verifikation

### Schnelltests

**twdev-Integration testen (2 Shifts):**
```bash
EMAIL_TO="test@example.com" SMTP_USER="test@example.com" SMTP_PASS="dummy" \
  python3 test_twdev_integration.py
```

**Maschinenblockade testen:**
```bash
EMAIL_TO="test@example.com" SMTP_USER="test@example.com" SMTP_PASS="dummy" \
  python3 test_machine_blockade.py
```

---

## ğŸ“Š Experimentelle Auswertung

### Batch-Experimente durchfÃ¼hren

**Alle finalen Experimente (12 Tests, ~24h Laufzeit):**
```bash
./run_all_final_experiments.sh
```

### Ergebnisse analysieren

**Zusammenfassung erstellen:**
```bash
python3 analyze_final_results.py
```

### Erzeugte Ausgaben

Nach dem Durchlauf werden folgende Dateien erstellt:

- **`experiments_overview.png`** - Ãœbersicht aller durchgefÃ¼hrten Experimente
- **`experiments_summary.csv`** - Tabellarische Zusammenfassung
- Detaillierte Metriken in der Datenbank (`experiments.db`)

---

## ğŸ“ Dokumentation

- **`README.md`** - Diese Datei (ProjektÃ¼bersicht, Setup, Nutzung)

---

## ğŸ”‘ Kernkonzepte der Implementierung (VERALTET - siehe ABSCHLUSSBERICHT.md)

### Alte Batch-Experiment-Diagramme (nicht mehr relevant)

Die folgenden Abschnitte beschreiben die alten isolierten Batch-Experimente.
Diese wurden durch die Rolling-Horizon-Integration ersetzt.

<details>
<summary>Klicken zum Anzeigen der alten Diagramm-Beschreibungen</summary>

### ğŸ“ˆ Diagramm 1: `batch_scatter_makespan_vs_tardiness.png` (VERALTET)

**Was zeigt dieses Diagramm?**

Ein Punktdiagramm (Scatter-Plot), das fÃ¼r jede der 100 Konfigurationen die **Gesamtdurchlaufzeit (Makespan)** auf der X-Achse gegen die **VerspÃ¤tungskosten (Tardiness)** auf der Y-Achse auftrÃ¤gt.

**Wie liest man dieses Diagramm?**

- **GrÃ¼ne gestrichelte Linie bei 930:** Der optimale Baseline-Makespan ohne StÃ¶rung. Das ist der bestmÃ¶gliche Wert, wenn keine Maschine ausfÃ¤llt.
- **Rote Punkte:** Konfigurationen mit zeitgewichteter Abweichung (`dev_mode=twdev`). Hier werden Ã„nderungen an nahen Operationen stÃ¤rker bestraft.
- **TÃ¼rkise Punkte:** Konfigurationen mit ungewichteter Abweichung (`dev_mode=dev`). Hier werden alle Operationen gleich behandelt.
- **PunktgrÃ¶ÃŸe:** Je grÃ¶ÃŸer der Punkt, desto hÃ¶her das VerspÃ¤tungs-Gewicht (w_t). GroÃŸe Punkte bedeuten, dass PÃ¼nktlichkeit in dieser Konfiguration hoch priorisiert wurde.
- **Goldener Stern:** Die beste ausgewogene Konfiguration, die sowohl niedrigen Makespan als auch niedrige VerspÃ¤tung erreicht.

**Konkrete Werte aus unseren Experimenten:**

| Markierung | Konfiguration | Makespan (Gesamtdurchlaufzeit) | VerspÃ¤tungskosten | Bedeutung |
|------------|---------------|--------------------------------|-------------------|-----------|
| Minimaler Makespan | #94 | **1136 Zeiteinheiten** | 11555 | KÃ¼rzeste Gesamtdurchlaufzeit aller Konfigurationen |
| Minimale VerspÃ¤tung | #57 | 1362 Zeiteinheiten | **2223** | PÃ¼nktlichste LÃ¶sung mit niedrigster VerspÃ¤tung |
| Beste Balance | #70 | 1185 Zeiteinheiten | 2234 | Optimaler Kompromiss zwischen beiden Zielen |

**Was bedeutet das?**

- Alle Punkte liegen **rechts** der grÃ¼nen Linie â†’ jede StÃ¶rung (Maschinenblockade) erhÃ¶ht die Gesamtdurchlaufzeit gegenÃ¼ber dem Optimum
- Es gibt einen **Trade-off (Zielkonflikt)**: Eine niedrige Gesamtdurchlaufzeit geht oft mit hÃ¶herer VerspÃ¤tung einher und umgekehrt
- Die beste Balance liegt bei einer Gesamtdurchlaufzeit von circa 1185 Zeiteinheiten, was **+27% Ã¼ber dem Baseline** von 930 liegt

---

### ğŸ“ˆ Diagramm 2: `batch_scatter_makespan_vs_deviation.png`

**Was zeigt dieses Diagramm?**

Die Gesamtdurchlaufzeit (Makespan) auf der X-Achse gegen die **Abweichungskosten (Deviation)** auf der Y-Achse â€“ also wie stark sich der neue Plan gegenÃ¼ber dem ursprÃ¼nglichen Baseline-Plan geÃ¤ndert hat.

**Wie liest man dieses Diagramm?**

- **PunktgrÃ¶ÃŸe:** Je grÃ¶ÃŸer der Punkt, desto hÃ¶her das Abweichungs-Gewicht (w_dev). GroÃŸe Punkte bedeuten, dass PlanstabilitÃ¤t in dieser Konfiguration hoch priorisiert wurde.
- Punkte **links unten** sind ideal: Das bedeutet wenig Verlust bei der Gesamtdurchlaufzeit UND wenig PlanÃ¤nderung gegenÃ¼ber dem Original.

**Konkrete Werte:**

| Konfiguration | Makespan (Gesamtdurchlaufzeit) | Abweichungskosten | Interpretation |
|---------------|--------------------------------|-------------------|----------------|
| #1 | 1271 Zeiteinheiten | 22.087 | Minimale PlanÃ¤nderung gegenÃ¼ber Baseline |
| #91 | 1269 Zeiteinheiten | 560.070 | Maximale PlanÃ¤nderung gegenÃ¼ber Baseline |
| #70 | 1185 Zeiteinheiten | 86.528 | Guter Kompromiss |

**Was bedeutet das?**

- HÃ¶here Abweichungs-Gewichte (w_dev) fÃ¼hren zu **hÃ¶heren gewichteten Kosten**, aber die **absolute PlanÃ¤nderung** (also wie viele Operationen tatsÃ¤chlich verschoben wurden) bleibt Ã¤hnlich
- Die Abweichungskosten variieren von circa 22.000 bis circa 560.000 â€“ das ist ein **Faktor von 25**! Das liegt daran, dass bei hÃ¶heren Gewichten jede kleine Ã„nderung viel teurer bewertet wird.

---

### ğŸ“ˆ Diagramm 3: `batch_scatter_tardiness_vs_deviation.png`

**Was zeigt dieses Diagramm?**

Den **Zielkonflikt (Trade-off)** zwischen PÃ¼nktlichkeit (VerspÃ¤tungskosten) und PlanstabilitÃ¤t (Abweichungskosten).

**Wie liest man dieses Diagramm?**

- **Farbskala (rechts):** 
  - Rote Punkte = VerspÃ¤tungs-fokussiert (VerhÃ¤ltnis VerspÃ¤tungs-Gewicht zu Abweichungs-Gewicht grÃ¶ÃŸer als 1)
  - GrÃ¼ne Punkte = Abweichungs-fokussiert (VerhÃ¤ltnis kleiner als 1)
- **Schwarze Rauten:** Die sogenannten **Pareto-optimalen** Konfigurationen. Das sind Konfigurationen, bei denen keine andere Konfiguration in **beiden** Dimensionen (VerspÃ¤tung UND Abweichung) besser ist.
- **Gestrichelte Linie:** Die approximierte **Pareto-Front** â€“ sie zeigt die Grenze des Machbaren.

**Konkrete Pareto-optimale Konfigurationen:**

| Konfiguration | VerspÃ¤tungs-Gewicht | Abweichungs-Gewicht | VerspÃ¤tungskosten | Abweichungskosten | Warum ist diese Konfiguration Pareto-optimal? |
|---------------|---------------------|---------------------|-------------------|-------------------|-----------------------------------------------|
| #1 | 1 | 1 | 2.370 | 22.087 | Hat die niedrigsten Abweichungskosten aller Konfigurationen |
| #70 | 1 | 2 | 2.234 | 86.528 | Beste Balance zwischen beiden Zielen |
| #57 | 1 | 2 | 2.223 | 52.968 | Hat die niedrigsten VerspÃ¤tungskosten aller Konfigurationen |

**Was bedeutet das?**

- Man kann **nicht** gleichzeitig beide Ziele minimieren â†’ Die Pareto-Front zeigt den bestmÃ¶glichen Kompromiss
- Bewegung entlang der Front: Weniger VerspÃ¤tung fÃ¼hrt zu mehr Abweichung (und umgekehrt)
- Konfigurationen **unterhalb** der Pareto-Front sind nicht erreichbar

---

### ğŸ“ˆ Diagramm 4: `batch_histograms_overview.png`

**Was zeigt dieses Diagramm?**

Vier Histogramme, die die **Verteilung** aller 100 Ergebnisse zeigen. So sieht man, wie hÃ¤ufig bestimmte Wertebereiche vorkommen.

**Die vier Teildiagramme im Detail:**

**Oben links: Verteilung der Gesamtdurchlaufzeit (Makespan)**
- **Rote gestrichelte Linie:** Der Baseline-Wert (930 Zeiteinheiten) â€“ das Optimum ohne StÃ¶rung
- **Orange Linie:** Der Mittelwert aller 100 Experimente (1247 Zeiteinheiten)
- Die meisten Werte liegen zwischen 1150 und 1350 Zeiteinheiten
- **Konkrete Werte:** 
  - Minimum: 1136 Zeiteinheiten
  - Maximum: 1452 Zeiteinheiten
  - Mittelwert: **1247 Zeiteinheiten (das ist +34% gegenÃ¼ber dem Baseline von 930)**

**Oben rechts: Verteilung der VerspÃ¤tungskosten (Tardiness)**
- Die Verteilung ist **zweigipflig**: 
  - Viele niedrige Werte zwischen circa 2.000 und 5.000 (von Konfigurationen mit niedrigem VerspÃ¤tungs-Gewicht)
  - Einige hohe Werte zwischen circa 20.000 und 25.000 (von Konfigurationen mit hohem VerspÃ¤tungs-Gewicht)
- **Konkrete Werte:**
  - Minimum: 2.223
  - Maximum: 27.640
  - Mittelwert: **8.711**

**Unten links: Verteilung der Abweichungskosten (Deviation)**
- Die Verteilung ist **stark rechtsschief**: Die meisten Werte liegen unter 100.000, aber es gibt AusreiÃŸer bis 700.000
- **Konkrete Werte:**
  - Minimum: 22.087
  - Maximum: 713.860
  - Mittelwert: **131.730**

**Unten rechts: Verteilung der Gesamtkosten (Objective)**
- Ã„hnlich wie die Abweichungskosten, da die Abweichung den grÃ¶ÃŸten Anteil an den Gesamtkosten ausmacht
- **Konkrete Werte:**
  - Minimum: 24.457
  - Maximum: 720.976
  - Mittelwert: **140.441**

---

### ğŸ“ˆ Diagramm 5: `batch_heatmaps_weights.png`

**Was zeigt dieses Diagramm?**

Drei Heatmaps (WÃ¤rmebilder), die den **Einfluss der Gewichte** auf die Ergebnisse zeigen.

**Die Achsen:**
- **Y-Achse:** VerspÃ¤tungs-Gewicht (w_t) mit Werten 1, 2, 5 und 10
- **X-Achse:** Abweichungs-Gewicht (w_dev) mit Werten 1, 2, 3, 5 und 10

**Linke Heatmap: Durchschnittliche Gesamtdurchlaufzeit (Makespan)**
- **Farbskala:** Gelb = niedrige Werte (gut), Rot = hohe Werte (schlecht)
- **Wichtige Erkenntnis:** Die Gesamtdurchlaufzeit ist **weitgehend unabhÃ¤ngig** von den Gewichten!
- Alle Felder zeigen Ã¤hnliche Werte zwischen circa 1.200 und 1.300 Zeiteinheiten
- **Bedeutung:** Die StÃ¶rung (Maschinenblockade) bestimmt die Gesamtdurchlaufzeit, nicht die Gewichte der Zielfunktion

**Mittlere Heatmap: Durchschnittliche VerspÃ¤tungskosten (Tardiness)**
- Zeigt einen klaren Trend: **Je hÃ¶her das VerspÃ¤tungs-Gewicht (w_t), desto hÃ¶her die gewichteten VerspÃ¤tungskosten**
- Bei VerspÃ¤tungs-Gewicht = 1: circa 2.000 bis 5.000
- Bei VerspÃ¤tungs-Gewicht = 10: circa 20.000 bis 25.000
- **Bedeutung:** Das ist ein **Skalierungseffekt**, keine echte Verbesserung der PÃ¼nktlichkeit! Die absolute VerspÃ¤tung in Minuten bleibt gleich, nur die gewichteten Kosten steigen.

**Rechte Heatmap: Durchschnittliche Abweichungskosten (Deviation)**
- Zeigt einen klaren Trend: **Je hÃ¶her das Abweichungs-Gewicht (w_dev), desto hÃ¶her die gewichteten Abweichungskosten**
- Bei Abweichungs-Gewicht = 1: circa 20.000 bis 50.000
- Bei Abweichungs-Gewicht = 10: circa 200.000 bis 500.000
- **Bedeutung:** Auch hier nur ein Skalierungseffekt, keine echte Reduktion der PlanÃ¤nderung!

---

### ğŸ“ˆ Diagramm 6: `batch_boxplots_parameters.png`

**Was zeigt dieses Diagramm?**

Sechs Box-Plots (Kastendiagramme), die den Einfluss **einzelner Parameter** auf die Ergebnisse isoliert darstellen. So kann man sehen, welcher Parameter welchen Effekt hat.

**Oben links: Gesamtdurchlaufzeit nach StÃ¶rungsdauer (block_until)**
- **X-Achse:** 30, 60, 90, 120, 150, 180 Minuten Maschinenblockade
- **Erkenntnis:** LÃ¤ngere Blockade fÃ¼hrt zu etwas hÃ¶herer Gesamtdurchlaufzeit, aber der Unterschied ist gering
- Alle Werte liegen deutlich Ã¼ber der Baseline-Linie bei 930 Zeiteinheiten (rot gestrichelt)

**Oben Mitte: VerspÃ¤tungskosten nach Liefertermin-Enge (due_tighten_min)**
- **X-Achse:** 0, 20, 40, 50, 100 Minuten, um die die Liefertermine enger gemacht wurden
- **Erkenntnis:** Engere Liefertermine fÃ¼hren zu **deutlich hÃ¶heren** VerspÃ¤tungskosten!
- Bei Verengung um 0 Minuten: circa 5.000 bis 10.000
- Bei Verengung um 100 Minuten: circa 20.000 bis 25.000
- **Bedeutung:** Unrealistisch enge Liefertermine fÃ¼hren zu hohen VerspÃ¤tungskosten. Die Liefertermine sollten realistisch gewÃ¤hlt werden.

**Oben rechts: Abweichungskosten nach Modus (ungewichtet vs. zeitgewichtet)**
- **Erkenntnis:** Der zeitgewichtete Modus (`twdev`) fÃ¼hrt zu **circa doppelt so hohen** Abweichungskosten wie der ungewichtete Modus (`dev`)
- Das ist beabsichtigt: Der zeitgewichtete Modus bestraft Ã„nderungen an nahen Operationen stÃ¤rker

**Unten links: Gesamtdurchlaufzeit nach blockierter Maschine**
- **X-Achse:** Maschinen M00, M03, M05
- Alle drei Maschinen zeigen Ã¤hnliche Gesamtdurchlaufzeiten zwischen circa 1.200 und 1.300 Zeiteinheiten
- M05 hat etwas mehr AusreiÃŸer nach oben
- **Bedeutung:** Alle getesteten Maschinen sind Ã¤hnlich kritisch fÃ¼r den Produktionsablauf

**Unten Mitte: Zeitgewichtete Abweichungskosten nach Zeitfenster (dev_window_min)**
- **X-Achse:** 240, 480, 720 Minuten (entspricht 4, 8 und 12 Stunden)
- **Erkenntnis:** GrÃ¶ÃŸeres Zeitfenster fÃ¼hrt zu **VIEL hÃ¶heren** zeitgewichteten Abweichungskosten!
- Bei 240 Minuten Zeitfenster: circa 80.000 bis 100.000
- Bei 720 Minuten Zeitfenster: circa 300.000 bis 600.000
- **Bedeutung:** Ein groÃŸes Zeitfenster bedeutet, dass mehr Operationen in den â€nahen" Bereich fallen und somit bei Ã„nderung hÃ¶her bestraft werden

**Unten rechts: Zeitgewichtete Abweichungskosten nach Bucket-GrÃ¶ÃŸe (dev_bucket_min)**
- **X-Achse:** 30, 60, 120 Minuten
- **Erkenntnis:** Kleinere Buckets fÃ¼hren zu hÃ¶heren Kosten
- Bei 30 Minuten Bucket-GrÃ¶ÃŸe: circa 300.000 bis 600.000
- Bei 120 Minuten Bucket-GrÃ¶ÃŸe: circa 100.000 bis 150.000
- **Bedeutung:** Feinere Zeiteinteilung bedeutet strengere Gewichtung nach zeitlicher NÃ¤he

---

## ğŸ† Optimales GewichtsverhÃ¤ltnis (VERALTET - siehe ABSCHLUSSBERICHT.md)

Basierend auf den 100 Experimenten ergibt sich folgendes optimales VerhÃ¤ltnis:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                             â”‚
â”‚   OPTIMALES VERHÃ„LTNIS:                                                                     â”‚
â”‚   VerspÃ¤tungs-Gewicht : VerfrÃ¼hungs-Gewicht : Abweichungs-Gewicht  =  1 : 1 : 2            â”‚
â”‚                                                                                             â”‚
â”‚   Erwartete Ergebnisse bei typischer StÃ¶rung (Maschine M00 blockiert 60-90 Minuten):       â”‚
â”‚   â€¢ Gesamtdurchlaufzeit: 1185 Zeiteinheiten (+27% gegenÃ¼ber Baseline 930)                  â”‚
â”‚   â€¢ VerspÃ¤tungskosten: circa 2.234 (niedrig)                                               â”‚
â”‚   â€¢ Abweichungskosten: circa 43.000 ungewichtet (moderat)                                  â”‚
â”‚                                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Warum dieses VerhÃ¤ltnis?

| Aspekt | Bei VerhÃ¤ltnis 1:1:2 | Bei VerhÃ¤ltnis 1:1:5 | Bei VerhÃ¤ltnis 1:1:10 |
|--------|----------------------|----------------------|-----------------------|
| Gesamtdurchlaufzeit | +27% gegenÃ¼ber Baseline | +29% gegenÃ¼ber Baseline | +34% gegenÃ¼ber Baseline |
| FlexibilitÃ¤t bei StÃ¶rungen | âœ… Hoch | âš ï¸ Mittel | âŒ Niedrig |
| Rechenzeit des Solvers | âœ… Schnell | âš ï¸ Mittel | âŒ Langsam |
| Absolute Verbesserung der PlanstabilitÃ¤t | Referenz | +1% | +3% |

**Fazit:** Ab einem Abweichungs-Gewicht grÃ¶ÃŸer als 2 gibt es kaum noch Verbesserung bei der absoluten PlanstabilitÃ¤t, aber die Kosten und die Rechenzeit steigen stark an. **Das VerhÃ¤ltnis 1:1:2 ist der optimale Kompromiss (Sweet Spot).**

---

</details>
